{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 2: Second-Level Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last notebook, we performed a first level analysis by using data from a single subject. In this notebook, we will now do a second-level analysis using up to $94$ subjects. If you are unsure what the difference is between a first and second level analysis, please read the [First-Level vs Second-Level Analysis](./nb_01_fmri_data_and_first_level_analysis.ipynb#First-Level-vs-Second-Level-Analysis) section of the notebook `01`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of Contents\n",
    "\n",
    " - [Notebook 0: Introduction](./nb_00_introduction.ipynb)\n",
    " - [Notebook 1: FMRI Data and First-Level Analysis](./nb_01_fmri_data_and_first_level_analysis.ipynb)\n",
    " - [**Notebook 2: Second-Level Analysis**](./nb_02_second_level_analysis.ipynb)\n",
    "   - [Getting Started](#Getting-Started)\n",
    "     - [Loading the Data](#Loading-the-Data)\n",
    "     - [MNI Space](#MNI-Space)\n",
    "     - [Glass Brain Plots and Displaying the Subject $t$-statistic Maps](#Glass-Brain-Plots-and-Displaying-the-Subject-$t$-statistic-Maps)\n",
    "   - [Second-Level Analysis: An Example](#Second-Level-Analysis:-An-Example)\n",
    "     - [Building $X$ and Fitting the Model](#Building-$X$-and-Fitting-the-Model)\n",
    "     - [Parametric Inference](#Parametric-Inference)\n",
    "     - [Non-Parametric Inference](#Non-Parametric-Inference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin by loading some relevant modules! If you did the previous notebooks and the `Introduction to Python` course, this should be feeling fairly familiar to you at this point. If not, feel free to ask one of the tutors what is going on here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import nilearn\n",
    "import nibabel as nib\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin, we will work with a dataset drawn from the ['Brainomics/Localizer' database](Brainomics/Localizer database), which investigated several different brain areas and stimuli (see [here](https://nilearn.github.io/modules/generated/nilearn.datasets.fetch_localizer_contrasts.html) for more details).\n",
    "\n",
    "For now, we'll focus on a task where subjects had to alternately press a button with their left and and their right hands. Let's download some data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.datasets import fetch_localizer_contrasts\n",
    "n_subjects = 16\n",
    "data = fetch_localizer_contrasts([\"left vs right button press\"], n_subjects,\n",
    "                                 get_tmaps=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we've just downloaded 16 $t$-statistic images, each of which was generated from a first-level analysis for a different subject. For each subject, the task and analysis conducted was identical, and now we wish to combine the subject-level results to get a single meaningful result which represents the group's response.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Previous Analysis and Registration to MNI Space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we get started, it is worth emphasizing that this data has undergone several previous stages of analysis. These included:\n",
    "\n",
    "- **Motion correction**: This step accounted for subjects moving their head.\n",
    "- **Regstration**: This step \"warped\" each subject's 4D data to standard atlas space\n",
    "- **First level model fitting**: At the first level effect size (i.e. $L\\beta^v$) and $T$-maps have already been produced.\n",
    "\n",
    "The second step in the above is new to us, and was not performed in the previous notebook. The results have been [\"registered\"](./nb_01_fmri_data_and_first_level_analysis.ipynb#Preprocessing) to MNI space. This means that all of the images have been transformed into a standard shape size and orientation known as MNI152 (You can read a bit more about this [here](https://www.lead-dbs.org/about-the-mni-spaces/)). \n",
    "\n",
    "For reference, you can have a look at the standard MNI152 template below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import image, plotting\n",
    "from nilearn.datasets import MNI152_FILE_PATH\n",
    "smooth_anat_img = image.smooth_img(MNI152_FILE_PATH, fwhm=3)\n",
    "\n",
    "# While we are giving a file name as input, the function returns\n",
    "# an in-memory object:\n",
    "plotting.plot_img(MNI152_FILE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glass Brain Plots and Displaying the Subject $t$-statistic Maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's have a look at our data! In the last notebook we were looking at volumes on a slice-by-slice basis. Here, we will take a slightly different approach and visualize our images as \"glass brain plots\". A glass brain plot is a nice way of visualizing all slices of a thresholded image laid on top of one another, and can be made using the `plot_glass_brain` function in nilearn. Try the below example!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import plotting\n",
    "\n",
    "# Get the subject data\n",
    "subjects = [subject_data[0] for subject_data in data['ext_vars']]\n",
    "\n",
    "# Set up a new figure with subplots\n",
    "fig, axes = plt.subplots(nrows=4, ncols=4,figsize=(15,15))\n",
    "\n",
    "# Loop through the T-statistic images, theshold each one and plot it.\n",
    "for cidx, tmap in enumerate(data['tmaps']):\n",
    "    plotting.plot_glass_brain(tmap, colorbar=False, threshold=2.0,\n",
    "                              title=subjects[cidx],\n",
    "                              axes=axes[int(cidx / 4), int(cidx % 4)],\n",
    "                              plot_abs=False, display_mode='z')\n",
    "fig.suptitle('Subjects T_map left-right button press')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above, we have one glass-brain plot per subject! As you can see it seems like there's a large amount of variation between subjects! In the next section, we will see if we can get anything meaninful out of the group activation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second-Level Analysis: An Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we've downloaded the images from $16$ first-level analyses. Now, let's have a look at how we can combine these at the second-level using `nilearn`!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building $X$ and Fitting the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For these subjects we simply want to find the average difference between the left and right button press. That is, we simply want to submit the contrast data to a one-sample $t$-test. \n",
    "\n",
    "Building the design matrix for the one-sample $t$-test analysis is fairly straightforward. We want to test the group average effect, so all we need in our model is an intercept. If you're not sure why the design matrix in this case is a column of ones, feel free to ask one of the tutors and we will happy go over this for you! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The design matrix this time only contains an intercept\n",
    "design_matrix = pd.DataFrame([1] * n_subjects,\n",
    "                             columns=['intercept'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the design matrix!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.plotting import plot_design_matrix\n",
    "\n",
    "# Create design matrix plot\n",
    "plot_design_matrix(design_matrix)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is much simpler than the design matrix we had in the first-level model! \n",
    "\n",
    "Okay, we are now ready to create a `SecondLevelModel` object. As with the `FirstLevelModel` in the previous notebook, we must first create the object, and then pass it the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.glm.second_level import SecondLevelModel\n",
    "second_level_model = SecondLevelModel(smoothing_fwhm=8.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike for the `FirstLevelModel`, we don't really have to specify all that much when we initialize the `SecondLevelModel`. \n",
    "\n",
    "Back in the [previous notebook](./nb_01_fmri_data_and_first_level_analysis.ipynb#Building-$X$-and-Fitting-the-Model), when we initialized the `FirstLevelModel` we had to set a load of parameters (e.g. `t_r`, `noise_model`, `standardize`, `hrf_model`, `drift_model`, `high_pass`) but most of these were to do with how we were modelling the behaviour *across time* (this is the answer to Question 3 of the previous notebook). \n",
    "\n",
    "In a second-level analysis, we are no longer dealing with timeseries and, as a result, things become a lot simpler!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to give the model our imaging data (the $L\\beta^v$ maps which were generated in the first level analyses) and our design matrix. Exactly as we did with our `FirstLevelModel` we can now fit the data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_level_model = second_level_model.fit(data['cmaps'],\n",
    "                                            design_matrix=design_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, by using `compute_contrast`, we can generate all the same images we were able to before! Let's quickly make a $Z$-map!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our contrast is very simple!\n",
    "L = [1]\n",
    "\n",
    "# Let's make our Z map!\n",
    "z_map = second_level_model.compute_contrast(L, output_type='z_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that, because our design matrix only contains one column, our parameter vector $\\beta$ only contains one element. As a result, the contrast vector $L$ contains just a single element as well; $L=[1]$. This is much simpler than what we had to do for the first-level analysis!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact, our model is so much simpler that nilearn can guess what contrast vector we need (i.e. it can guess out that we probably want to use $L=[1]$)! As a result we can rerun the code above without $L$ and nilearn will still do the same thing! Let's try this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make our Z map!\n",
    "z_map = second_level_model.compute_contrast(output_type='z_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parametric Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we now have our unthresholded $Z$-map; let's try thresholding it using some methods we met in the [previous notebook](./nb_01_fmri_data_and_first_level_analysis.ipynb#Thresholding-your-Results). First, let's look at an uncorrected threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.glm import threshold_stats_img\n",
    "\n",
    "# Make a new threshold object\n",
    "_, threshold = threshold_stats_img(z_map, alpha=.05, height_control='fpr')\n",
    "\n",
    "# Print the threshold\n",
    "print('Uncorrected p<0.05 threshold: %.3f' % threshold)\n",
    "\n",
    "\n",
    "# Apply it to our statistic map\n",
    "display = plotting.plot_glass_brain(\n",
    "    z_map, threshold=threshold, colorbar=True, plot_abs=False,\n",
    "    title='group left-right button press (unc p<0.05)')\n",
    "plotting.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh wow! There's a lot of activation there! Can you explain why this is?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using what you learnt in the previous notebook and the above code, try thresholding the $Z$-map first using a `Bonferroni` threshold and then using an `FDR` threshold. Make a glass brain plot for each result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which of your thresholds is more *conservative*, and why? You may have to look back at the [previous notebook](./nb_01_fmri_data_and_first_level_analysis.ipynb#Thresholding-your-Results) for help!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might be getting sick of us asking you this at this point but it is important; Why, in practice, should you not threshold your results over and over again in this way? ([Hint](https://en.wikipedia.org/wiki/Data_dredging))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-Parametric Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above examples use *parametric* approaches. This means they make assumptions about the parameters of the population distribution from which the sample is drawn (e.g. they assume that $Y\\sim N(X\\beta,\\Sigma)$). In this section, we will try something a little different; a *non-parametric* permutation test!\n",
    "\n",
    "A permutation test is a *data-driven* way of correcting for multiple comparisons without making the same strict assumptions you would when using a parametric threshold. If you want to know more about the mechanics behind a permutation test you can check out [this paper](https://www.fil.ion.ucl.ac.uk/spm/doc/papers/NicholsHolmes.pdf) or ask one of the tutors for more details!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The permutation test controls Family Wise Error rate, which we met in the [previous notebook](./nb_01_fmri_data_and_first_level_analysis.ipynb#Thresholding-your-Results). To see why permutation testing is popular in the fMRI community, let's compare FWE-corrected results produced by permutation testing to FWE-corrected results we would obtain using the method we investigated in the previous notebook; Bonferroni.\n",
    "\n",
    "To get started, let's make a Bonferonni-corrected $p$-value image for comparison at the $\\alpha = 10\\%$ significance level.\n",
    "\n",
    "We will start by making an image of $-log_{10}(Vp^v))$, where $V$ is the number of voxels in the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nilearn.image import get_data, math_img\n",
    "\n",
    "# Compute the p value volume\n",
    "p_val = second_level_model.compute_contrast([1], output_type='p_value')\n",
    "\n",
    "# Work out the number of vocels in the image (what's going on here? see if you can work it out)\n",
    "n_voxels = np.sum(get_data(second_level_model.masker_.mask_img_))\n",
    "\n",
    "# Correcting the p-values for multiple testing and taking negative logarithm\n",
    "neg_log_pval = math_img(\"-np.log10(np.minimum(1, img * \" + str(n_voxels) + \"))\",\n",
    "                        img=p_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a lot going on here so let's go through this carefully.\n",
    "\n",
    "To begin, let's talk about what the code is actually doing. In the above, we have first computed the $p$-value image in the same way we did in the previous notebook. After that we worked our $V$, the number of voxels. After this we computed an image of $-log_{10}(min(1,Vp^v))$ using the nilearn `math_img` function, which allows us to generate images using mathematic expressions.\n",
    "\n",
    "\n",
    "Why have we done this? Well, let's think about what a Bonferonni correction does. A Bonferroni correction says we are only interested in the voxels, $v$, which satisfy;\n",
    "\n",
    "$$\\frac{\\alpha}{V}< p^v$$\n",
    "\n",
    "By rearranging and taking logarithms we can see that this is equivalent to:\n",
    "\n",
    "$$-\\log_{10}(\\alpha) > -\\log_{10}(Vp^v)$$\n",
    "\n",
    "Okay... but why take the logarithm in the above? Taking the negative logarithm of the $p$-values might seem a bit random here, but it is purely for illustration purposes. Viewing things on a log scale allows us to see the differences between very small $p$-values a bit more clearly. You will often see $p$-value images displayed in this way in the literature.\n",
    "\n",
    "Finally, let's talk about the minimum. Why did we add a `min` in here? Well, this is really just to trick nilearn into plotting what we want. By default, if nilearn sees negative values in an image it will apply thresholding as though we were doing a two-tailed test. This minimum simply prevents the values in the $\\log_{10}$ image from taking negative values and stops nilearn from going into two-tailed mode when displaying the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our significance level, alpha\n",
    "alpha = 0.05\n",
    "\n",
    "# Convert alpha to the -log10 scale\n",
    "threshold = -np.log10(alpha)\n",
    "\n",
    "# Title of the plot\n",
    "title = ('Group left-right button press: \\n'\n",
    "         'parametric test (FWER < ' + str(int(100*alpha)) + '%)')\n",
    "\n",
    "# Display the plot\n",
    "display = plotting.plot_glass_brain(\n",
    "    neg_log_pval, colorbar=True, display_mode='z', plot_abs=False, vmax=3,\n",
    "    cut_coords=[0], threshold=threshold, title=title)\n",
    "plotting.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so the above is just the result we would get doing the same Bonferonni correction that we met in the previous notebook (it just became a bit more convoluted because we wanted to display it in a different way)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try performing a $5\\%$ multiple comparisons correction using a permutation test instead! Nilearn provides us with the `non_parametric_inference` function to achieve this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.glm.second_level import non_parametric_inference\n",
    "\n",
    "# Get unmasked -log10 p values.\n",
    "neg_log_pvals_permuted_ols_unmasked = \\\n",
    "    non_parametric_inference(data['cmaps'],\n",
    "                             design_matrix=design_matrix,\n",
    "                             model_intercept=True, n_perm=1000,\n",
    "                             two_sided_test=False,\n",
    "                             smoothing_fwhm=8.0, n_jobs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a look at the [documentation](https://nilearn.github.io/modules/generated/nilearn.glm.second_level.non_parametric_inference.html) for the `non_parametric_inference` and see if you can understand what each of the above input arguments is. By doing your own research into permutation testing, try and explain why each of these arguments is needed for the permutation test. Ask one of the tutors if you still aren't sure!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, finally, let's threshold our non-parametric p-values at the $5\\%$ level the same way we thresholded our Bonferroni corrected $p-$values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Title of the plot\n",
    "title = ('Group left-right button press: \\n'\n",
    "         'permutation test (FWER < ' + str(int(100*alpha)) + '%)')\n",
    "\n",
    "# Display the plot\n",
    "display = plotting.plot_glass_brain(\n",
    "    neg_log_pvals_permuted_ols_unmasked, colorbar=True, vmax=3,\n",
    "    display_mode='z', plot_abs=False, cut_coords=cut_coords,\n",
    "    threshold=threshold, title=title)\n",
    "plotting.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The permutation testing method has given us a much less conservative region, but because of the theory behind permutation testing, it still controls the Family-Wise Error rate! This is a great result!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
